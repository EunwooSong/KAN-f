import re
import random
import kor_noise.hangul as hangul
from kor_noise.add_final import add_final
from kor_noise.alter_word import alter_word
from kor_noise.shiftkey import shiftkey
from kor_noise.shuffle_korean import shuffle_korean
from eng_noise.eng_noise import *

# ë³€í™˜ ë…¸ì´ì¦ˆ ë¦¬ìŠ¤íŠ¸
noise_list = [add_final, alter_word, shiftkey, shuffle_korean]
noise_list_en = [shuffle_korean, word_eng_noise]
test_document = 'ì´ê²ƒì€ KAN-f ë…¸ì´ì¦ˆ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ë¬¸ìž¥ìž…ë‹ˆë‹¤. ì´ëŸ°ì´ëŸ°... ë–¡ í•˜ë‚˜ ì£¼ë©´ ì•ˆ ìž¡ì•„ ë¨¹ì§€!'

def convert_text(text:str, seed:int = 1) -> str:
    """
    ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì— ëžœë¤í•œ ë…¸ì´ì¦ˆë¥¼ ì ìš©í•©ë‹ˆë‹¤.

    Parameters:
    text (str): ë³€í™˜í•  í…ìŠ¤íŠ¸

    Returns:
    str: ë³€í™˜ëœ í…ìŠ¤íŠ¸

    Examples:
    >>> split_sentences("ì•ˆë…•í•˜ì„¸ìš”. ë°˜ê°‘ìŠµë‹ˆë‹¤!", ".!")
    'ì•ˆì„¸ë…•í•˜ìš”. ë°˜ê°‘ìŠµë‹ˆë‹¤!'
    """
    sentences = split_sentences(text);
    new_text = ''
    for sentence in sentences:
        new_text += convert_sentence(sentence, seed)
    return new_text

def convert_text_eng(text:str, seed: int = 1) -> str:
    """
    ì£¼ì–´ì§„ ì˜ì–´ í…ìŠ¤íŠ¸ì— ëžœë¤í•œ ë…¸ì´ì¦ˆë¥¼ ì ìš©í•©ë‹ˆë‹¤.
    """

    sentences = split_sentences(text)
    new_text = ''
    for sentence in sentences:
        new_text += convert_sentence_eng(sentence, seed)
    return new_text 

def split_sentences(text, punctuations=['.', ',', '!', '?', ';','\n']) -> dict:
    """
    ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ ë¬¸ìž¥ìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
    ë¬¸ìž¥ê³¼ í•´ë‹¹ êµ¬ë‘ì ì„ dict í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.

    Parameters:
    text (str): êµ¬ë¶„í•  í…ìŠ¤íŠ¸
    punctuations (str, optional): ë¬¸ìž¥ êµ¬ë¶„ ê¸°ì¤€ì´ ë˜ëŠ” êµ¬ë‘ì  ë¬¸ìžì—´
    (ê¸°ë³¸ê°’: ['.', ',', '!', '?', ';','\n'])

    Returns:
    list: êµ¬ë¶„ëœ ë¬¸ìž¥ê³¼ í•´ë‹¹ êµ¬ë‘ì ì„ ë‹´ì€ dictë“¤ì˜ ë¦¬ìŠ¤íŠ¸

    Examples:
    >>> split_sentences("ì•ˆë…•í•˜ì„¸ìš”. ë°˜ê°‘ìŠµë‹ˆë‹¤!", ".!")
    [{'sentence': 'ì•ˆë…•í•˜ì„¸ìš”', 'punc': '.'}, {'sentence': ' ë°˜ê°‘ìŠµë‹ˆë‹¤', 'punc': '!'}]
    """
    # êµ¬ë‘ì ì„ ê¸°ì¤€ìœ¼ë¡œ ìŠ¬ë¼ì´ì‹±í•  pos êµ¬í•˜ê¸°
    sentences = []
    punc_index = [0]
    is_punc = False
    for i, char in enumerate(text):
        if i == len(text) - 1:
            punc_index.append(i+1)
            break

        if char in punctuations:
            is_punc = True
            continue

        if is_punc and (char != ' '):
            punc_index.append(i)
            is_punc = False
            continue
    
    # ìŠ¬ë¼ì´ì‹± ì§„í–‰
    punc_group = zip(punc_index[:-1:], punc_index[1::])
    for s, e in punc_group:
        sentences.append(text[s:e])
    
    # ë³€í™˜í•  ë¬¸ìž¥ê³¼ êµ¬ë‘ì ìœ¼ë¡œ ë¶„ë¦¬
    result = []
    
    for sentence in sentences:
        for i, char in enumerate(sentence):
            if char in punctuations:
                result.append({"sentence": sentence[:i], 'punc': sentence[i:]})
                break
            elif i+1 == len(sentence):
                result.append({"sentence": sentence, 'punc': ''})
                break

    return result


def convert_sentence_eng(sentence: dict, seed: int) -> str:
    """
    ë¬¸ìž¥ ë‹¨ìœ„ë¡œ ë…¸ì´ì¦ˆë¥¼ ì ìš©í•©ë‹ˆë‹¤. (ì˜ì–´ ì „ìš©)
    """
    words = str.split(sentence['sentence'], ' ')
    noise = random.choice(noise_list_en)
    result = []

    for word in words:
        result.append(convert_word(word, noise, seed))
    return ' '.join(result) + sentence['punc']

def convert_sentence(sentence: dict, seed: int) -> str:
    """
    ë¬¸ìž¥ ë‹¨ìœ„ë¡œ ë…¸ì´ì¦ˆë¥¼ ì ìš©í•©ë‹ˆë‹¤. (í•œê¸€ ì „ìš©)
    """
    words = str.split(sentence['sentence'], ' ')
    noise = random.choice(noise_list)
    result = []
    for word in words:
        result.append(convert_word(word, noise, seed))
    return ' '.join(result) + sentence['punc']


def convert_word(word: str, noise, seed: int=1) -> str:
    conv_word = []
    index = 0
    
    for char in word:
        if hangul.is_hangul(char):
            if index == len(conv_word):
                conv_word.append(char)
            else:
                conv_word[index] += char
        else:
            index += 1
            conv_word.append(char)
            index += 1
    
    result = []
    for seq in conv_word:
        if hangul.is_word_hangul(seq):
            result.append(noise(seq, seed))
        else:
            result.append(seq)
    
    return ''.join(result)

def convert_word_en(word: str, noise, seed: int=1) -> str:
    conv_word = []
    index = 0
    
    for char in word:
        if char.isalpha():
            if index == len(conv_word):
                conv_word.append(char)
            else:
                conv_word[index] += char
        else:
            index += 1
            conv_word.append(char)
            index += 1
    
    result = []
    for seq in conv_word:
        if seq.isalpha():
            result.append(noise(seq, seed))
        else:
            result.append(seq)
    
    return ''.join(result)

random.seed(99)
print(convert_text('ì•ˆë…•í•˜ì„¸ìš”. ë°˜ê°‘ìŠµë‹ˆë‹¤!'))
print(convert_text('êº¼. êº¼. êº¼. êº¼. êº¼. '))
print(convert_text(test_document))
print(convert_text(test_document))
print(convert_text(test_document))
print(convert_text(test_document))
print(convert_text(test_document))
print(convert_text(test_document))

print(convert_text_eng("Don't you love ðŸ¤— Transformers? We sure do."))
